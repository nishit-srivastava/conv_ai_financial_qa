{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d907ad-7415-4bf5-a2f5-7d038efd6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856c2e58-d70e-4d88-8380-d68ba8d7e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf9a1495-8d05-4f45-8210-a7d526ef3151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7fec082-3cb4-46b1-942a-589374856cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = Path(\"../data/raw_pdfs/TCS_2023-24.pdf\")\n",
    "if not pdf_path.exists(): raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d8b465d-64c4-4030-8269-0c53f94b3446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Extracting text with PyMuPDF ===\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 2. Extract text with PyMuPDF\n",
    "# -------------------------------\n",
    "print(\"=== Extracting text with PyMuPDF ===\")\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "all_pages_text = []\n",
    "for page_num, page in enumerate(doc, start=1):\n",
    "    text = page.get_text(\"text\")\n",
    "    all_pages_text.append({\n",
    "        \"page\": page_num,\n",
    "        \"text\": text.strip()\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d100b9ae-9bff-42a9-ad89-d3b64f24171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Extracting tables with Camelot ===\n",
      "Found 11 tables in PDF.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 3. Extract tables with Camelot\n",
    "# -------------------------------\n",
    "print(\"\\n=== Extracting tables with Camelot ===\")\n",
    "tables = camelot.read_pdf(str(pdf_path), pages=\"all\", flavor=\"lattice\")  \n",
    "\n",
    "print(f\"Found {tables.n} tables in PDF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75ca031d-6a4c-4758-ae35-48152fe8aa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21192\\2299427856.py:9: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  rows_as_dicts = df.to_dict(orient=\"records\")\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21192\\2299427856.py:9: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  rows_as_dicts = df.to_dict(orient=\"records\")\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21192\\2299427856.py:9: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  rows_as_dicts = df.to_dict(orient=\"records\")\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21192\\2299427856.py:9: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  rows_as_dicts = df.to_dict(orient=\"records\")\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21192\\2299427856.py:9: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  rows_as_dicts = df.to_dict(orient=\"records\")\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21192\\2299427856.py:9: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  rows_as_dicts = df.to_dict(orient=\"records\")\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21192\\2299427856.py:9: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  rows_as_dicts = df.to_dict(orient=\"records\")\n"
     ]
    }
   ],
   "source": [
    "all_tables_json = []\n",
    "for i, table in enumerate(tables, start=1):\n",
    "    df = table.df  # Pandas DataFrame\n",
    "    df.columns = df.iloc[0]  # First row as header\n",
    "    df = df[1:]  # Remove header row\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Convert each row to key-value dict based on headers\n",
    "    rows_as_dicts = df.to_dict(orient=\"records\")\n",
    "    \n",
    "    all_tables_json.append({\n",
    "        \"table_number\": i,\n",
    "        \"page\": table.page,  # Camelot stores page number\n",
    "        \"data\": rows_as_dicts\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61f91d4a-6288-4ed4-96cb-6badb58283af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. Combine into a single JSON\n",
    "# -------------------------------\n",
    "result_json = {\n",
    "    \"text_pages\": all_pages_text,\n",
    "    \"tables\": all_tables_json\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17cb2007-fcf7-49bb-9bd3-4d8010051224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ JSON saved to financial_statement.json\n"
     ]
    }
   ],
   "source": [
    "output_path = \"financial_statement.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(result_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n✅ JSON saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97d8f83a-ff9b-4ec8-a42e-10d0505e7b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No table detected — try OCR next.\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "pdf_path = \"../data/raw_pdfs/TCS_2023-24.pdf\"\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    page = pdf.pages[0]\n",
    "\n",
    "    # Debug: See all words with positions\n",
    "    words = page.extract_words()\n",
    "    #print(words[:10])  # sample output\n",
    "\n",
    "    # Try table extraction with custom settings\n",
    "    table = page.extract_table({\n",
    "        \"vertical_strategy\": \"lines\",\n",
    "        \"horizontal_strategy\": \"lines\",\n",
    "        \"intersection_tolerance\": 5\n",
    "    })\n",
    "\n",
    "    if table:\n",
    "        for row in table:\n",
    "            print(row)\n",
    "    else:\n",
    "        print(\"No table detected — try OCR next.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "03d4e6f3-eefb-4409-948f-6131ce533a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TATA CONSULTANCY SERVICES LIMITED Audited Consolidated Statement of Financial Results (= crore) Three month period ended Revenue from operations 61,237 60,583 59,162 2,40,893 OTHER COMPREHENSIVE INCOME (OCI) Non-controlling interests Other comprehensive income for the period attributable to: Total comprehensive income for the period attributable to: Paid up equity share capital (Face value: %1 per share) Earnings per equity share:- Basic and diluted (%) Interim dividend on equity shares (%) Final dividend on equity shares Total dividend on equity shares Total equity dividend percentage\n",
      "Registered Office: Floor, Nirmal Building, Nariman Point, Mumbai 400 021 March 31, December 31, March 31, March 31, March 31, Other income 1,157 86. , 4,422 3,449 Items that will not be reclassified subsequently to profit or loss Shareholders of the Company Shareholders of the Company Total reserves (including Non-controlling interests) Dividend per share (Par value each)\n",
      "CIN: L22210MH1995PLC084781 2024 2023 2023 2024 2023 TOTAL INCOME | 61,445 Remeasurement of defined employee benefit plans Non-controlling interests Non-controlling interests\n",
      "Tel: +91 22 6778 9595 e-mail: investor.relations@tcs.com Website: www.tcs.com Expenses Net change in fair values of investments in equity shares\n",
      "Employee benefit expenses carried at fair value through OCI\n",
      "Cost of equipment and software licences Income tax on items that will not be reclassified subsequently to profit\n",
      "Finance costs or loss\n",
      "Depreciation and amortisation expense Items that will be reclassified subsequently to profit or loss\n",
      "Other expenses Net change in fair values of investments other than equity\n",
      "TOTAL EXPENSES shares carried at fair value through OCI\n",
      "PROFIT BEFORE EXCEPTIONAL ITEM AND TAX Net change in intrinsic value of derivatives designated as cash\n",
      "Exceptional item flow hedges\n",
      "Settlement of legal claim Net change in time value of derivatives designated as cash\n",
      "PROFIT BEFORE TAX flow hedges\n",
      "Tax expense Exchange differences on translation of financial statements of\n",
      "Current tax foreign operations\n",
      "Deferred tax Income tax on items that will be reclassified subsequently to profit or\n",
      "TOTAL TAX EXPENSE loss\n",
      "PROFIT FOR THE PERIOD TOTAL OTHER COMPREHENSIVE INCOME / (LOSSES)\n",
      "TOTAL COMPREHENSIVE INCOME FOR THE PERIOD\n",
      "Profit for the period attributable to:\n",
      "Shareholders of the Company\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# If on Windows, specify path to Tesseract exe\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "pdf_path = \"../data/raw_pdfs/TCS_2023-24.pdf\"\n",
    "\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "\n",
    "pix = doc[0].get_pixmap(dpi=300)\n",
    "img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
    "\n",
    "ocr_data = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
    "\n",
    "rows = {}\n",
    "n_boxes = len(ocr_data['text'])\n",
    "\n",
    "for i in range(n_boxes):\n",
    "    if int(ocr_data['conf'][i]) > 50:  # only keep good confidence\n",
    "        line_num = ocr_data['line_num'][i]\n",
    "        word = ocr_data['text'][i].strip()\n",
    "        if word:\n",
    "            rows.setdefault(line_num, []).append(word)\n",
    "\n",
    "# Convert to list of rows\n",
    "row_list = [\" \".join(words) for _, words in sorted(rows.items())]\n",
    "\n",
    "# Print result row-wise\n",
    "for r in row_list:\n",
    "    print(r) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "751a24be-9b5c-4b86-a9be-49b70972bd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['March 31, December 31, March 31, March 31, March 31,']\n",
      "['2024 2023 2023 2024 2023']\n",
      "['Revenue from operations', '61,237 60,583 59,162 2,40,893 2,25,458']\n",
      "['Other income', '1,157 862 1,175 4,422 3,449']\n",
      "['TOTAL INCOME 62,394 61,445 60,337 2,45,315 2,28,907']\n",
      "['Expenses']\n",
      "['Employee benefit expens es', '35,138 34,722 33,687 1,40,131 1,27,522']\n",
      "['Cos t of equipment and s oftware licences', '1,561 1,173 620 3,702 1,881']\n",
      "['Finance cos ts', '226 230 272 778 779']\n",
      "['Depreciation and amortis ation expens e', '1,246 1,233 1,286 4,985 5,022']\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "import re\n",
    "\n",
    "pdf_path = Path(\"../data/raw_pdfs/TCS_2023-24.pdf\")\n",
    "\n",
    "reader = PdfReader(str(pdf_path))\n",
    "all_rows = []\n",
    "\n",
    "for page_num, page in enumerate(reader.pages, start=1):\n",
    "    text = page.extract_text()\n",
    "    if not text:\n",
    "        continue\n",
    "    lines = text.split(\"\\n\")\n",
    "\n",
    "    for line in lines:\n",
    "        # Always keep the line, even if only one column\n",
    "        parts = re.split(r\"\\s{2,}\", line.strip())\n",
    "        all_rows.append(parts)\n",
    "\n",
    "# Create JSON-like structure\n",
    "result_json = {\"rows\": all_rows}\n",
    "\n",
    "# Save JSON\n",
    "output_path = \"financial_statement_.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(result_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Preview first 10 rows\n",
    "for r in all_rows[:10]:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f0033-b5a5-4d0f-abc9-40b8a4d1116d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conv_ai_env",
   "language": "python",
   "name": "conv_ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
